# ğŸ¥ Healthcare Child Malnutrition Prediction

This repository presents an end-to-end machine learning workflow for predicting **child malnutrition** using health, demographic, and anthropometric data. Through **data preprocessing**, **exploratory data analysis**, **classification**, **regression**, **clustering**, and **model optimization**, the project aims to assist health professionals and researchers in identifying children at risk of malnutrition.

---

## ğŸ“ Dataset Used

- **Original Dataset Source**: [Multiple Indicator Cluster Surveys (MICS) - UNICEF](https://www.kaggle.com/datasets/usharengaraju/child-malnutrition-unicef-dataset/data)
- **Cleaned Dataset**: [`cleaned_malnutrition_dataset.csv`](https://github.com/Safia-ElSabbagh/Healthcare-Child-Malnutrion-prediction/blob/main/Milestone%201/Cleaned%20Survey%20Data.csv)

---

## ğŸ¯ Objective

The main goals of this project are to:
- **Classify** whether a child is malnourished based on key health and socio-economic factors.
- **Predict** continuous outcomes (e.g., malnutrition scores) using regression.
- **Cluster** children into nutritional groups for exploratory analysis.
- **Interpret model behavior** using SHAP and feature importance.
- **Optimize model performance** through hyperparameter tuning.

---

## ğŸ› ï¸ Tools & Technologies

| Category | Tools/Libraries |
|---------|-----------------|
| Programming | Python 3 |
| Data Handling | Pandas, NumPy |
| Visualization | Matplotlib, Seaborn, SHAP |
| Machine Learning | Scikit-learn, XGBoost |
| Optimization | GridSearchCV |
| Dimensionality Reduction | PCA |
| Deployment | Joblib |

---

## ğŸ“ˆ Project Pipeline

### 1. ğŸ“Š Data Preprocessing & Cleaning

- **Removed missing values** and handled outliers.
- **Encoded categorical features** (e.g., gender, region) using label encoding.
- **Scaled numerical features** (e.g., weight, height, age) using `StandardScaler`.
- Split data into **training** and **testing** sets using stratified sampling.

### 2. ğŸ” Exploratory Data Analysis (EDA)

- Box plots, histograms, and heatmaps were used to:
  - Detect class imbalance.
  - Visualize feature distributions.
  - Examine correlations (e.g., between weight and malnutrition).
- Insight: Malnutrition was strongly associated with **underweight**, **height-for-age**, and **socioeconomic status**.

### 3. ğŸ¤– Classification Models

We trained several models to classify whether a child is malnourished:

| Model | Description |
|-------|-------------|
| Logistic Regression | Baseline linear classifier. Simple but effective. |
| Decision Tree | Tree-based model for interpretable rules. |
| Random Forest | Ensemble of trees with better generalization. |
| K-Nearest Neighbors | Distance-based method; sensitive to scaling. |
| XGBoost | High-performing gradient boosting classifier. |

- **Evaluation metrics**: Accuracy, Precision, Recall, F1-Score, ROC-AUC.
- **Best model**: XGBoost showed the highest performance and interpretability via SHAP.

### 4. ğŸ“‰ Regression Models

Used to **predict malnutrition score** (continuous outcome) instead of binary label.

| Model | Performance Metrics (on test set) |
|-------|-----------------------------------|
| Linear Regression | MAE, MSE, RMSE, RÂ² |
| Lasso Regression | Penalized model to reduce overfitting |
| Decision Tree Regressor | Nonlinear regressor, interpretable |

- Visualization of residuals and RÂ² revealed Decision Tree Regressor performed best on non-linear patterns.

### 5. ğŸ“Š Unsupervised Learning (Clustering)

Applied **K-Means clustering** to group children based on similar attributes:

- Used **Elbow Method** to determine optimal k (=5).
- Applied **PCA** for 2D visualization of clusters.
- **Silhouette Score**: 0.58 (moderate separation).
- Insights:
  - Cluster 1: Underweight, high risk of malnutrition.
  - Cluster 2: Healthy weight, low risk.
- Plotted malnourished distribution across clusters.

### 6. ğŸ” Model Interpretation

#### âœ… SHAP (SHapley Additive exPlanations)
- Applied to XGBoost model to understand feature contributions.
- Features like **weight**, **height**, and **mother's education** had the strongest impact.

#### ğŸ“Š Feature Importance
- Visualized importance scores from XGBoost before and after optimization.

### 7. âš™ï¸ Hyperparameter Tuning

Used **GridSearchCV** to improve XGBoost:

- Tuned `n_estimators`, `max_depth`, `learning_rate`, etc.
- Compared ROC curves before vs. after tuning.
- Reduced **overfitting** with `gamma`, `reg_alpha`, `reg_lambda`.

| Metric | Before | After |
|--------|--------|-------|
| AUC | 0.88 | 0.92 |
| Test Accuracy | 84% | 88% |

### 8. ğŸ§  Final Model & Deployment

- Final optimized XGBoost model saved with **Joblib**.
- Can be loaded for real-time predictions or deployed in a web application.

---

## ğŸ“Œ Results Summary

- XGBoost outperformed other models in both classification and interpretability.
- Regression models revealed feature influence on malnutrition scores.
- K-Means clustering helped uncover hidden patterns in the dataset.
- SHAP and PCA enhanced model transparency and stakeholder trust.

---

## ğŸ“ Folder Structure
ğŸ“¦ Healthcare-Child-Malnutrion-Prediction
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ child_health_raw.csv
â”‚ â””â”€â”€ child_health_cleaned.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ malnutrition_prediction_colab.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ optimized_xgboost_model.pkl
â”‚
â”œâ”€â”€ images/
â”‚ â””â”€â”€ plots, SHAP, PCA visuals
â”‚
â””â”€â”€ README.md

## ğŸ‘¨â€ğŸ’» Contributors

| Name | GitHub Profile |
|------|----------------|
| Mariam Mohamed | [@202201223](https://github.com/202201223) |
| Amira Yasser | [@amirayasser1](https://github.com/amirayasser1) |
| Safia ElSabbagh | [@Safia-ElSabbagh](https://github.com/Safia-ElSabbagh) |

